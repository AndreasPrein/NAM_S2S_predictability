{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMME_PR_prediction.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    File name: NMME_PR_prediction.ipynb\\n    Author: Andreas Prein\\n    E-mail: prein@ucar.edu\\n    Date created: 04.03.2021\\n    Date last modified: 04.03.2021\\n\\n    ##############################################################\\n    Purpos:\\n\\n    1) Read in NMME precipitation forecasts in focus catchments\\n\\n    2) Save monthly catchment average precipitation for future processing\\n\\n'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "    File name: NMME_PR_prediction.ipynb\n",
    "    Author: Andreas Prein\n",
    "    E-mail: prein@ucar.edu\n",
    "    Date created: 04.03.2021\n",
    "    Date last modified: 04.03.2021\n",
    "\n",
    "    ##############################################################\n",
    "    Purpos:\n",
    "\n",
    "    1) Read in NMME precipitation forecasts in focus catchments\n",
    "\n",
    "    2) Save monthly catchment average precipitation for future processing\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dateutil import rrule\n",
    "import datetime\n",
    "import glob\n",
    "from netCDF4 import Dataset\n",
    "import sys, traceback\n",
    "import dateutil.parser as dparser\n",
    "import string\n",
    "from pdb import set_trace as stop\n",
    "import numpy as np\n",
    "import numpy.ma as ma\n",
    "import os\n",
    "from mpl_toolkits import basemap\n",
    "import pickle\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as colors\n",
    "import matplotlib as mpl\n",
    "import pylab as plt\n",
    "import random\n",
    "import scipy.ndimage as ndimage\n",
    "import matplotlib.gridspec as gridspec\n",
    "from mpl_toolkits.basemap import Basemap, cm\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import matplotlib.gridspec as gridspec\n",
    "from pylab import *\n",
    "import string\n",
    "from matplotlib.patches import Polygon\n",
    "from matplotlib.collections import PatchCollection\n",
    "import shapefile\n",
    "import shapely.geometry\n",
    "# import descartes\n",
    "import shapefile\n",
    "import math\n",
    "from scipy.stats.kde import gaussian_kde\n",
    "from math import radians, cos, sin, asin, sqrt\n",
    "from scipy import spatial\n",
    "import scipy.ndimage\n",
    "import matplotlib.path as mplPath\n",
    "from scipy.interpolate import interp1d\n",
    "import time\n",
    "from math import atan2, degrees, pi\n",
    "import scipy\n",
    "import scipy.ndimage as ndimage\n",
    "import scipy.ndimage.filters as filters\n",
    "import csv\n",
    "import pygrib\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "# from netcdftime import utime\n",
    "from scipy.ndimage import gaussian_filter\n",
    "import scipy.ndimage.filters as filters\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from datetime import timedelta\n",
    "import shapefile as shp\n",
    "\n",
    "#### speed up interpolation\n",
    "import scipy.interpolate as spint\n",
    "import scipy.spatial.qhull as qhull\n",
    "import numpy as np\n",
    "import h5py\n",
    "import xarray as xr\n",
    "\n",
    "def interp_weights(xy, uv,d=2):\n",
    "    tri = qhull.Delaunay(xy)\n",
    "    simplex = tri.find_simplex(uv)\n",
    "    vertices = np.take(tri.simplices, simplex, axis=0)\n",
    "    temp = np.take(tri.transform, simplex, axis=0)\n",
    "    delta = uv - temp[:, d]\n",
    "    bary = np.einsum('njk,nk->nj', temp[:, :d, :], delta)\n",
    "    return vertices, np.hstack((bary, 1 - bary.sum(axis=1, keepdims=True)))\n",
    "\n",
    "def interpolate(values, vtx, wts):\n",
    "    return np.einsum('nj,nj->n', np.take(values, vtx), wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_shapefile(sf):\n",
    "    \"\"\"\n",
    "    Read a shapefile into a Pandas dataframe with a 'coords' \n",
    "    column holding the geometry information. This uses the pyshp\n",
    "    package\n",
    "    \"\"\"\n",
    "    fields = [x[0] for x in sf.fields][1:]\n",
    "    records = sf.records()\n",
    "    shps = [s.points for s in sf.shapes()]\n",
    "    df = pd.DataFrame(columns=fields, data=records)\n",
    "    df = df.assign(coords=shps)\n",
    "    return df\n",
    "\n",
    "def MakeShapefile(Regions,\n",
    "                 LonW,\n",
    "                 LatW,\n",
    "                 sShapefiles):\n",
    "    \n",
    "    rgrGridCells=[(LonW.ravel()[ii],LatW.ravel()[ii]) for ii in range(len(LonW.ravel()))]\n",
    "    HUC4_WRF=np.zeros((LonW.shape[0]*LonW.shape[1]))\n",
    "    for bs in range(len(Regions)):\n",
    "        Basins = [Regions[bs]]\n",
    "        for ba in range(len(Basins)):\n",
    "#             print('        process '+Basins[ba])\n",
    "            sf = shp.Reader(sShapefiles+Basins[ba])\n",
    "            df = read_shapefile(sf)\n",
    "            for sf in range(df.shape[0]):\n",
    "                ctr = df['coords'][sf]\n",
    "                if len(ctr) > 10000:\n",
    "                    ctr=np.array(ctr)[::100,:] # carsen the shapefile accuracy\n",
    "                else:\n",
    "                    ctr=np.array(ctr)\n",
    "                grPRregion=mplPath.Path(ctr)\n",
    "                TMP=np.array(grPRregion.contains_points(rgrGridCells))\n",
    "                HUC4_WRF[TMP == 1]=bs+1\n",
    "    HUC4_WRF=np.reshape(HUC4_WRF, (LatW.shape[0], LatW.shape[1]))\n",
    "    return HUC4_WRF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "#                            USER INPUT SECTION\n",
    "mo = 0 # model implemented are [0,1,2]\n",
    "\n",
    "DataDirERAI='/glade/campaign/mmm/c3we/prein/Projects/Arizona_WTing/data/HandK/'\n",
    "\n",
    "# Basins\n",
    "Basins=['AZ_West', 'AZ_East', 'NM_North','NM_South'] \n",
    "Region=Basins\n",
    "sSubregion='/glade/u/home/prein/projects/Arizona_WTing/Shapefiles/'\n",
    "\n",
    "NMME_dir = '/glade/collections/cdg/data/nmme/output1/'\n",
    "IFS_dir = '/glade/campaign/mmm/c3we/ECMWF/'\n",
    "# center/model name, ensemble members, file convention\n",
    "NMME_models = [['NCAR/CESM1',10,'month_CESM1'], #['CCCMA','NASA-GMAO','NCAR/CESM1', 'NCEP','NOAA-GFDL','UM-RSMAS']\n",
    "               ['NASA-GMAO/GEOS-5',10,'day_GEOS-5'], # maskes out below surface areas --> use 650 hPa level\n",
    "               ['UM-RSMAS/CCSM4', 10, 'mon_CCSM4'],\n",
    "               ['CCCMA/CanCM4', 10, 'Amon_CanCM4'],  # only has 675 hPa data\n",
    "               ['IFS', 25, 'day_CanCM4']] # only 7 month forecast but 25 members\n",
    "ConstantFile = [NMME_dir+'NCAR/CESM1/19820101/day/atmos/hus/hus_day_CESM1_19820101_r4i1p1_19820100-19821231.nc4',\n",
    "               NMME_dir+'NASA-GMAO/GEOS-5/19820101/day/atmos/hus/hus_day_GEOS-5_19820101_r1i1p1.nc',\n",
    "               NMME_dir+'UM-RSMAS/CCSM4/20050801/day/atmos/hus/hus_day_CCSM4_20050801_r10i1p1_20050801-20060731.nc',\n",
    "               NMME_dir+'CCCMA/CanCM4/19840101/day/atmos/v20181101/hus/hus_day_CanCM4_198401_r10i1p1_19840101-19841231.nc4',\n",
    "               IFS_dir+'20050601/Q_GDS0_ISBL/Q_GDS0_ISBL_day_ECMWF_mem01_20050601.nc']\n",
    "DataDir = [NMME_dir,\n",
    "          NMME_dir,\n",
    "          NMME_dir,\n",
    "          NMME_dir,\n",
    "          IFS_dir]\n",
    "# for each variable we have the general varname, the netCDF var name, and the pressure level (-1 means 2D field), netCDF varname\n",
    "ImputVars=[['PR','precip','precip','mon'],\n",
    "            ['PR','pr','pr','day'],\n",
    "            ['PR','precip','PRECIP','mon'],\n",
    "            ['PR','prlr','prlr','mon'],\n",
    "            ['PR','prec','TP_GDS0_SFC','day']]\n",
    "\n",
    "SaveDir='/glade/campaign/mmm/c3we/prein/Projects/Arizona_WTing/data/NMME/PR/'\n",
    "\n",
    "MONTHS=[6,7,8,9,10] # [1,2,3,4,5,6,7,8,9,10,11,12]\n",
    "StartMonths=[2,3,4,5,6]\n",
    "\n",
    "dStartDay=datetime.datetime(int(1982), 1, 1,12)\n",
    "dStopDay=datetime.datetime(int(2010), 12, 31,12)\n",
    "rgdTimeDD = pd.date_range(dStartDay, end=dStopDay, freq='d')\n",
    "rgdTimeMM = pd.date_range(dStartDay, end=dStopDay, freq='m')\n",
    "rgiYY=np.unique(rgdTimeDD.year)\n",
    "rgdTimeDD = rgdTimeDD[np.isin(rgdTimeDD.month, MONTHS)]\n",
    "rgdTimeMM = rgdTimeMM[np.isin(rgdTimeMM.month, MONTHS)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loop over Models and Regions and Calculate Monsoon Season PR in Basins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "work on NCAR/CESM1\n",
      "    process 1982\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1983\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1984\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1985\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1986\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1987\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1988\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1989\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1990\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1991\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1992\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1993\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1994\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1995\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1996\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1997\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1998\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1999\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2000\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2001\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2002\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2003\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2004\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2005\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2006\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2007\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2008\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2009\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 2010\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "work on NASA-GMAO/GEOS-5\n",
      "    process 1982\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1983\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1984\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1985\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1986\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1987\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1988\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1989\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1990\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1991\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n",
      "        month 5\n",
      "        month 6\n",
      "    process 1992\n",
      "        month 2\n",
      "        month 3\n",
      "        month 4\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "\nBoolean array must have the same shape as the data along this dimension.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c81d5cda6560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    106\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 107\u001b[0;31m                         \u001b[0mDATAact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImputVars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miSouth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miNort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miWest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miEast\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    108\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable._toma\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable._check_safecast\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/glade/u/apps/dav/opt/python/3.7.5/gnu/8.3.0/pkg-library/20200417/lib/python3.7/site-packages/netCDF4/utils.py\u001b[0m in \u001b[0;36m_safecast\u001b[0;34m(a, b)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mdef\u001b[0m \u001b[0m_safecast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;31m# check to see if array a can be safely cast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c81d5cda6560>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    107\u001b[0m                         \u001b[0mDATAact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImputVars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTime\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miSouth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miNort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miWest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miEast\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m                     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m                         \u001b[0mDATAact\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mncid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mImputVars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0miTime\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miSouth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miNort\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0miWest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0miEast\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mnetCDF4/_netCDF4.pyx\u001b[0m in \u001b[0;36mnetCDF4._netCDF4.Variable.__getitem__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/glade/u/apps/dav/opt/python/3.7.5/gnu/8.3.0/pkg-library/20200417/lib/python3.7/site-packages/netCDF4/utils.py\u001b[0m in \u001b[0;36m_StartCountStride\u001b[0;34m(elem, shape, dimensions, grp, datashape, put, use_get_vars)\u001b[0m\n\u001b[1;32m    249\u001b[0m                 msg=\"\"\"\n\u001b[1;32m    250\u001b[0m Boolean array must have the same shape as the data along this dimension.\"\"\"\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatnonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mea\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m         \u001b[0;31m# an iterable (non-scalar) integer array.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: \nBoolean array must have the same shape as the data along this dimension."
     ]
    }
   ],
   "source": [
    "PR_basins_NMME = np.zeros((len(rgiYY), len(MONTHS), len(StartMonths), len(NMME_models), 25, len(Basins))); PR_basins_NMME[:] = np.nan\n",
    "\n",
    "# ----- Load ERA data for constraining region ------\n",
    "ERA_data = '/glade/campaign/mmm/c3we/prein/Projects/Arizona_WTing/data/HandK/ERA-Interim_PRISM_data13514_1502_1982-2018_Q850_JJASO.npz'\n",
    "DATA = np.load(ERA_data)\n",
    "rgrLonT = DATA['LonWT']\n",
    "rgrLatT = DATA['LatWT']\n",
    "\n",
    "for mo in range(len(NMME_models)):\n",
    "    print('work on '+str(NMME_models[mo][0]))\n",
    "    if ImputVars[mo][3] == 'mon':\n",
    "        FREQ = 'm'\n",
    "    elif ImputVars[mo][3] == 'day':\n",
    "        FREQ = 'd'\n",
    "    # read NMME Grid\n",
    "    sERAconstantFields='/glade/work/prein/reanalyses/ERA-Interim/ERA_Inerim_stationary-files_75x75.nc'\n",
    "    # read the ERA-Interim elevation\n",
    "    ncid=Dataset(sERAconstantFields, mode='r')\n",
    "    rgrLat75=np.squeeze(ncid.variables['latitude'][:])\n",
    "    rgrLon75=np.squeeze(ncid.variables['longitude'][:])\n",
    "    rgrHeight=(np.squeeze(ncid.variables['z'][:]))/9.81\n",
    "    rgrLSM=(np.squeeze(ncid.variables['lsm'][:]))\n",
    "    ncid.close()\n",
    "    rgdTimeDD_Full = pd.date_range(datetime.datetime(int(1979), 1, 1,12), end=datetime.datetime(int(2017), 12, 31,12), freq='d')\n",
    "\n",
    "    # read NMME coordinates\n",
    "    ncid=Dataset(ConstantFile[mo], mode='r')\n",
    "    if 'lon' in list(ncid.variables.keys()):\n",
    "        rgrLonS=np.squeeze(ncid.variables['lon'][:])\n",
    "        rgrLatS=np.squeeze(ncid.variables['lat'][:])\n",
    "    elif 'LON' in list(ncid.variables.keys()):\n",
    "        rgrLonS=np.squeeze(ncid.variables['LON'][:])\n",
    "        rgrLatS=np.squeeze(ncid.variables['LAT'][:])\n",
    "    elif 'g0_lon_4' in list(ncid.variables.keys()):\n",
    "        rgrLonS=np.squeeze(ncid.variables['g0_lon_4'][:])\n",
    "        rgrLatS=np.squeeze(ncid.variables['g0_lat_3'][:])\n",
    "    ncid.close()\n",
    "    rgrLonSF, rgrLatSF = np.meshgrid(rgrLonS, rgrLatS)\n",
    "    rgrLonSF[rgrLonSF>180] = rgrLonSF[rgrLonSF>180]-360\n",
    "\n",
    "    if NMME_models[mo][0] == 'IFS':\n",
    "        rgrLatSF = rgrLatSF[::-1] # IFS lat runs from N to S\n",
    "\n",
    "    # get the region of interest\n",
    "    iAddCells= 10 # grid cells added to subregion\n",
    "    iWest=np.argmin(np.abs(rgrLonT.min() - rgrLonSF[0,:]))-iAddCells\n",
    "    iEast=np.argmin(np.abs(rgrLonT.max() - rgrLonSF[0,:]))+iAddCells\n",
    "    iNort=np.argmin(np.abs(rgrLatT.max() - rgrLatSF[:,0]))+iAddCells\n",
    "    iSouth=np.argmin(np.abs(rgrLatT.min() - rgrLatSF[:,0]))-iAddCells\n",
    "\n",
    "    rgrLonS=rgrLonSF[iSouth:iNort,iWest:iEast]\n",
    "    rgrLatS=rgrLatSF[iSouth:iNort,iWest:iEast]\n",
    "    \n",
    "    ### Calculate mask file for subregions\n",
    "    MASK = MakeShapefile(Basins,\n",
    "                 rgrLonS,\n",
    "                 rgrLatS,\n",
    "                 sSubregion)\n",
    "        \n",
    "\n",
    "    for yy in range(len(rgiYY)):\n",
    "        print('    process '+str(rgiYY[yy]))\n",
    "        for mm in range(len(StartMonths)):\n",
    "            print('        month '+str(StartMonths[mm]))\n",
    "            TIMEstamp = str(rgiYY[yy])+str(StartMonths[mm]).zfill(2)+'01'\n",
    "            dStartACT=datetime.datetime(rgiYY[yy], StartMonths[mm], 1,0)\n",
    "            if NMME_models[mo][0] in ['NCAR/CESM1','UM-RSMAS/CCSM4','CCCMA/CanCM4']:\n",
    "                dStopACT = dStartACT + relativedelta(months=+12) - timedelta(days=1)\n",
    "                rgdTimeACT = pd.date_range(dStartACT, end=dStopACT, freq=FREQ)\n",
    "            elif NMME_models[mo][0] == 'IFS':\n",
    "                dStopACT = dStartACT + relativedelta(months=+7)\n",
    "                rgdTimeACT = pd.date_range(dStartACT, end=dStopACT, freq=FREQ)\n",
    "            else:\n",
    "                dStopACT = dStartACT + relativedelta(months=+9) - timedelta(days=1)\n",
    "                rgdTimeACT = pd.date_range(dStartACT, end=dStopACT, freq=FREQ)\n",
    "            \n",
    "            if NMME_models[mo][0] == 'CCCMA/CanCM4':\n",
    "                DirNameAct = DataDir[mo]+NMME_models[mo][0]+'/'+TIMEstamp+'/'+ImputVars[mo][3]+'/atmos/v20181101/'+ImputVars[mo][1]+'/'\n",
    "            elif NMME_models[mo][0] == 'IFS':\n",
    "                if (rgiYY[yy] >= 1993) & (StartMonths[mm] >= 4):\n",
    "                    DirNameAct = DataDir[mo]+'/'+TIMEstamp+'/'+ImputVars[mo][1]+'/'\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                DirNameAct = DataDir[mo]+NMME_models[mo][0]+'/'+TIMEstamp+'/'+ImputVars[mo][3]+'/atmos/'+ImputVars[mo][1]+'/'\n",
    "            \n",
    "            for en in range(NMME_models[mo][1]):\n",
    "                YYYYMMDD_start = str(rgdTimeACT[0].year)+str(rgdTimeACT[0].month).zfill(2)+'00' #str(rgdTimeACT[0].day).zfill(2)\n",
    "                YYYYMMDD_stop = str(rgdTimeACT[-1].year)+str(rgdTimeACT[-1].month).zfill(2)+'*' #str(rgdTimeACT[-1].day).zfill(2)\n",
    "                if NMME_models[mo][0] == 'CCCMA/CanCM4':\n",
    "                    TIMEstamp = str(rgiYY[yy])+str(StartMonths[mm]).zfill(2)\n",
    "                if NMME_models[mo][0] != 'IFS':\n",
    "                    try:\n",
    "                        FileName = glob.glob(DirNameAct+ImputVars[mo][1]+'_'+NMME_models[mo][2]+'_'+TIMEstamp+'_r'+str(en+1)+'i1p1*'+'.nc*')[0]\n",
    "                    except:\n",
    "                        print('    not found - '+DirNameAct+ImputVars[mo][1]+'_'+NMME_models[mo][2]+'_'+TIMEstamp+'_r'+str(en+1)+'i1p1*'+'.nc*')\n",
    "                        continue\n",
    "                else:\n",
    "                    FileName = glob.glob(DirNameAct+ImputVars[mo][1]+'_day_ECMWF_mem'+str(en+1).zfill(2)+'*.nc')[0]\n",
    "                iTime = np.isin(rgdTimeACT.month, MONTHS)\n",
    "                # read the data\n",
    "                ncid=Dataset(FileName, mode='r')\n",
    "                if NMME_models[mo][0] == 'IFS':\n",
    "                    DATAact=np.squeeze(ncid.variables[ImputVars[mo][2]][:,:,iTime,:,:])[:,::-1,:][:,iSouth:iNort,iWest:iEast]\n",
    "                elif NMME_models[mo][0] == 'NASA-GMAO/GEOS-5':\n",
    "                    try:\n",
    "                        DATAact=np.squeeze(ncid.variables[ImputVars[mo][2]][iTime,:,iSouth:iNort,iWest:iEast])\n",
    "                    except:\n",
    "                        DATAact=np.squeeze(ncid.variables[ImputVars[mo][2]][iTime[:-1],:,iSouth:iNort,iWest:iEast])\n",
    "                else:\n",
    "                    try:\n",
    "                        DATAact=np.squeeze(ncid.variables[ImputVars[mo][2]][iTime,iSouth:iNort,iWest:iEast])\n",
    "                    except:\n",
    "                        # some models do not have leap years\n",
    "                        DATAact=np.squeeze(ncid.variables[ImputVars[mo][2]][iTime[:-1],iSouth:iNort,iWest:iEast])\n",
    "                ncid.close()\n",
    "                \n",
    "                if NMME_models[mo][0] == 'IFS':\n",
    "                    # calculate daily precipitation from accumulation\n",
    "                    PR_IFS = DATAact[1:,:,:]-DATAact[:-1,:,:]\n",
    "                    PR_IFS = np.append(PR_IFS[0,:,:][None,:,:],PR_IFS, axis=0)\n",
    "                    DATAact = PR_IFS\n",
    "                \n",
    "                # calculate monthly means if data is daily\n",
    "                if ImputVars[mo][3] == 'day':\n",
    "                    MON_dat = np.array([np.mean(DATAact[rgdTimeACT[iTime].month == MONTHS[ii],:,:], axis=0) for ii in range(len(MONTHS))])\n",
    "                    DATAact = MON_dat\n",
    "                    \n",
    "                # average monthly precipitation over catchments\n",
    "                for ba in range(len(Basins)):\n",
    "                    PR_basins_NMME[:,yy,:,mm,mo,en,ba] = np.mean(DATAact[:,MASK == (ba+1)], axis=(1))\n",
    "\n",
    "np.savez(SaveDir+'NMME_PR-forecasts_Monsoon-Basins.npz',\n",
    "        years=rgiYY,\n",
    "        months = MONTHS,\n",
    "        ForecastStartMonths = StartMonths,\n",
    "        models = NMME_models,\n",
    "        basins = Basins,\n",
    "        precipitation = PR_basins_NMME,\n",
    "        precip_dims = 'year,month,start-month,model,ensemble-member,basin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29, 5, 5, 5, 25, 4)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PR_basins_NMME.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SaveDir+'NMME_PR-forecasts_Monsoon-Basins.npz'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load PRISM and calculate basin averages for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Mask first\n",
    "ncid=Dataset('/glade/campaign/mmm/c3we/prein/observations/PRISM/data/PR/PRISM_daily_ppt_2014.nc', mode='r') # open the netcdf file\n",
    "rgrLatPR=np.squeeze(ncid.variables['lat'][:])\n",
    "rgrLonPR=np.squeeze(ncid.variables['lon'][:])\n",
    "ncid.close()\n",
    "\n",
    "MASK = MakeShapefile(Basins,\n",
    "                 rgrLonPR,\n",
    "                 rgrLatPR,\n",
    "                 sSubregion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the PRISM data\n",
    "rgrPRdata = np.zeros((len(rgiYY), len(MONTHS), len(Basins))); rgrPRdata[:] = np.nan\n",
    "for yy in range(len(rgiYY)):\n",
    "    print('working on '+str(rgiYY[yy]))\n",
    "    rgdTimeYY = pd.date_range(datetime.datetime(rgiYY[0]+yy, 1, 1,0), end=datetime.datetime(rgiYY[0]+yy, 12, 31,23), freq='d')\n",
    "    rgiDD=np.where(((rgdTimeYY.year == rgiYY[0]+yy) & (np.isin(rgdTimeYY.month, MONTHS))))[0]\n",
    "    ncid=Dataset('/glade/campaign/mmm/c3we/prein/observations/PRISM/data/PR/PRISM_daily_ppt_'+str(rgiYY[0]+yy)+'.nc', mode='r') # open the netcdf file\n",
    "    PR_PRISM_DD = np.squeeze(ncid.variables['PR'][rgiDD,:])\n",
    "    ncid.close()\n",
    "    PR_PRISM_MM = np.array([np.mean(PR_PRISM_DD[rgdTimeYY[rgiDD].month == MONTHS[ii],:,:], axis=0) for ii in range(len(MONTHS))])\n",
    "    # calcualte averages over regions\n",
    "    for ba in range(len(Basins)):\n",
    "        rgrPRdata[yy,:,ba] = np.mean(PR_PRISM_MM[:,MASK == (ba+1)], axis=(1))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez(SaveDir+'PRISM_PR-observations_Monsoon-Basins.npz',\n",
    "        years=rgiYY,\n",
    "        months = MONTHS,\n",
    "        basins = Basins,\n",
    "        precipitation = rgrPRdata,\n",
    "        precip_dims = 'year,month,basin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/glade/campaign/mmm/c3we/prein/Projects/Arizona_WTing/data/NMME/PR/PRISM_PR-observations_Monsoon-Basins.npz'"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SaveDir+'PRISM_PR-observations_Monsoon-Basins.npz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
